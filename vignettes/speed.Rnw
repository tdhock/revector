\documentclass{article}

\usepackage[cm]{fullpage}
\usepackage{amsmath,amssymb}
\newcommand{\pkg}[1]{\textbf{#1}}
\newcommand{\code}[1]{\texttt{#1}}

\begin{document}

%\VignetteIndexEntry{Speed comparisons}
\title{Speed comparisons}
\author{Toby Dylan Hocking}
\maketitle

This package was motivated by the following text processing
problem. For each of $n=625442$ rows in \code{data(genotypes}), Ref
gives one allele and Alt gives a comma-separated list of alleles, and
genotype is two of these alleles concatenated together. The goal is to
extract these two alleles, resulting in a $n\times 2$ character matrix.

<<setup>>=
library(revector)
library(microbenchmark)
library(ggplot2)
library(dplyr)
data(genotypes)
geno.ex <- genotypes[c(11, 26, 98, 52434, 70150, 129, 1, 29, 5),]
want <- cbind(c("G", "A", "CCA", "ATAT", "AGC", "ATTTT", NA, NA, NA),
              c("G", "G", "CCACA", "A", "AGC", "ATTTT", NA, NA, NA))
print(cbind(geno.ex, want))
@ 

One way to do this is by using a different regular expression for each
row.

<<regex>>=
pattern <- function(x){
  group.pat <- with(x, sprintf("%s|%s", Ref, gsub(",", "|", Alt)))
  sprintf("^(%s)(%s)$", group.pat, group.pat)
}
cbind(geno.ex[,1:2], pattern(geno.ex))
@ 

After defining the regular expression, we have a choice of several R
functions to use.

<<parsers>>=
parsers <- list(sub.strsplit=function(x){
  pat <- pattern(x)
  space <- rep(NA, length(x))
  for(i in 1:nrow(x)){
    space[i] <- sub(pat[i], "\\1 \\2", x[i,"genotype"])
  }
  res <- matrix(NA, length(space), 2)
  not.na <- space != "NN"
  res[not.na,] <- do.call(rbind, strsplit(space[not.na], " "))
  res
},regexec.regmatches=function(x){
  pat <- pattern(x)
  res <- matrix(NA, length(pat), 2)
  for(i in 1:nrow(x)){
    subject <- x[i,"genotype"]
    match <- regexec(pat[i], subject)
    ch <- regmatches(subject, match)[[1]]
    if(length(ch)){
      res[i,] <- ch[-1]
    }
  }
  res
},str_match_each=function(x){
  pat <- pattern(x)
  str_match_each(x$geno, pat)
})
lines.of.code <- sapply(parsers, function(fun){
  length(as.character(attr(fun, "srcref")))
})
check.correct <- function(fun, data){
  res <- fun(data)
  ## Check that all NN/NAs are detected correctly.
  is.nn <- is.na(res[,1])
  nn <- data[is.nn,]
  stopifnot(nn$genotype == "NN")
  ## Check that all others are detected correctly.
  not.nn.geno <- data.frame(data)[!is.nn,"genotype"]
  not.nn.parsed <- paste0(res[!is.nn, 1], res[!is.nn, 2])
  stopifnot(identical(not.nn.geno, not.nn.parsed))
}
margs <- list()
for(method in names(parsers)){
  print(method)
  check.correct(parsers[[method]], geno.ex)
  margs[[method]] <- substitute(parsers$m(geno.data), list(m=method))
}
## Already at this small data size there is definitely a difference.
geno.data <- geno.ex
do.call(microbenchmark, margs)
@ 

The code above runs the different methods on the small data table, and
checks to make sure that it extracts the correct information. Because
there was no error, we know that they all return the same, correct
answer.

However, the methods differ in terms of speed. The microbenchmark
package ran each method neval times, and it is clear that
\verb+revector::str_match_each+ is the fastest by an order of
magnitude. This is because it processes the entire vector of regular
expressions in C code, avoiding the overhead of repeatedly calling
sub/strplit/regexec/regmatches from R code.

<<repeatable,fig=TRUE>>=
## Try only the complicated expressions.
complicated <- genotypes[nchar(genotypes$geno) > 2,]
seed.times <- data.frame()
for(size in c(5, 10, 50)){
  for(seed in 1:10){
    set.seed(seed)
    picked <- sample(nrow(complicated), size)
    geno.data <- complicated[picked,]
    bench <- do.call(microbenchmark, margs)
    seed.times <- rbind(seed.times, data.frame(bench, size, seed))
  }
}
scales <- data.frame(seconds=1, label="1 second")
repeatable <- ggplot()+
  geom_point(aes(factor(seed), log10(time/1e9)), data=seed.times)+
  facet_grid(size ~ expr, labeller=function(var, val){
    if(var == "size"){
      sprintf("%d patterns", as.integer(val))
    }else{
      paste(val)
    }
  })+
  theme_bw()+
  theme(panel.margin=grid::unit(0, "cm"))+
  geom_hline(aes(yintercept=log10(seconds)), data=scales)+
  geom_text(aes(y=log10(seconds), label=label), data=scales, vjust=1, x=5)
print(repeatable)
@ 

The figure above shows the amount of time it takes to process a random
set of $n$ patterns and strings, where $n$ is given on the right panel
title. It is clear that the timings vary little between different
random seeds/data subsets.

<<scaling,fig=TRUE>>=
times <- data.frame()
set.seed(1)
for(size in c(5, 10, 50#, 100, 500, 1000, 5000, 10000
              )){
  print(size)
  picked <- sample(nrow(complicated), size)
  geno.data <- complicated[picked,]
  bench <- do.call(microbenchmark, margs)
  times <- rbind(times, data.frame(bench, size))
}
stats <- times %>%
  group_by(expr, size) %>%
  mutate(seconds=time/1e9) %>%
  summarise(min=min(seconds), max=max(seconds))
scales$size <- (max(stats$size)+min(stats$size))/2
bands <- ggplot()+
  geom_ribbon(aes(size, ymin=min, ymax=max, fill=expr),
              data=stats, alpha=1/2)+
  geom_hline(aes(yintercept=seconds), data=scales)+
  geom_text(aes(size, seconds, label=label), data=scales, vjust=1)+
  scale_x_log10()+
  scale_y_log10()
print(bands)

@ 

Finally, the figure above shows timings of the different methods as a
function of data set size. It is clear that
\verb+revector::str_match_each+ is the fastest method to process these
data.

\end{document}
